
% \begin{lemma} \label{lem:rho}
%     \begin{align}
%         \frac{1}{M} \summ{m=1}{M} \E \norm{\mc{g}^m_t - g^m_t}^2
%         &\leq
%         \sigma^2 + 2 \rho L^2 (\bar{F}_t - F_*)
%     \end{align}
% \end{lemma}
% \begin{proof}
%     \begin{align}
%         \frac{1}{M} \summ{m=1}{M} \E \norm{\mc{g}^m_t - g^m_t}^2
%         &\overset{~\ref{ass:ass_2}}{\leq}
%         \sigma^2 + \frac{\rho}{M} \summ{m=1}{M} \norm {g^m_t}^2 \\
%         &=
%         \sigma^2 + \frac{\rho}{M} \summ{m=1}{M} \norm {\nabla F(x^m_t) - \nabla F(x_*)}^2 \\
%         &\leq
%         \sigma^2 + \frac{2 \rho L^2}{M} \summ{m=1}{M} {F(x^m_t) - F_*} \\
%         &\leq 
%         \sigma^2 + 2 \rho L^2 (\bar{F}_t - F_*)
%     \end{align}
% \end{proof}



\begin{lemma} \label{lem:rho_2}
    \begin{align}
        \frac{1}{M} \summ{m=1}{M} \E \norm{\mc{g}^m_t - g^m_t}^2
        &\leq
        \sigma^2 + \rho L^2 V_t + \rho L^2 \norm{r_t}^2
    \end{align}
\end{lemma}
\begin{proof}
    \begin{align}
        \frac{1}{M} \summ{m=1}{M} \E \norm{\mc{g}^m_t - g^m_t}^2
        &\overset{~\ref{ass:ass_2}}{\leq}
        \sigma^2 + \frac{\rho}{M} \summ{m=1}{M} \norm {g^m_t}^2 \\
        &=
        \sigma^2 + \frac{\rho}{M} \summ{m=1}{M} \norm {\nabla F(x^m_t) - \nabla F(x_*)}^2 \\
        &\leq
        \sigma^2 + \frac{\rho L^2}{M} \summ{m=1}{M} \norm{x^m_t - x_*}^2 \\
        &=
        \sigma^2 + \frac{\rho L^2}{M} \summ{m=1}{M} \norm{x^m_t - \bar{x}_t + \bar{x}_t - x_*}^2 \\
        &=
        \sigma^2 + \frac{\rho L^2}{M} \summ{m=1}{M} \left( \norm{x^m_t - \bar{x}_t}^2
        + \norm{\bar{x}_t - x_*}^2 + 2\inner{x^m_t - \bar{x}_t}{\bar{x}_t - x_*} \right) \\
        &=
        \sigma^2 + \frac{\rho L^2}{M} \summ{m=1}{M} \left( \norm{x^m_t - \bar{x}_t}^2
        + \norm{\bar{x}_t - x_*}^2 \right) \\
        &= \sigma^2 + \rho L^2 \left( V_t + \norm{r_t}^2 \right)
    \end{align}
\end{proof}



\begin{lemma} \label{lem:var_red}
    Variance reduction:
    \begin{align}
        \E \norm{\bar{\mc{g}}_t - \bar{g}_t}^2 
        \leq 
        \frac{\sigma^2}{M} + \frac{\rho L^2 }{M} V_t  + \frac{\rho L^2 }{M} \norm{r_t}^2
    \end{align}
\end{lemma}
\begin{proof} In the second equality we use that $g^m_t$ on each device are independent, and in the first inequality we use Lemma~\ref{lem:rho_2}.
    \begin{align}
        \E \norm{\bar{\mc{g}}_t - \bar{g}_t}^2 
        &=
        \E \norm{\fsumm{m=1}{M}{\mc{g}^m_t - g^m_t}}^2 \\
        &=
        \frac{1}{M^2} \summ{m=1}{M} \E \norm{\mc{g}^m_t - g^m_t}^2 \\
        &\leq
        \frac{\sigma^2}{M} + \frac{\rho L^2 }{M} V_t  + \frac{\rho L^2 }{M} \norm{r_t}^2
    \end{align}
\end{proof}



\begin{lemma} \label{lem:lemma_Vt}

$\,$ 
    \begin{itemize}
        \item[(a)] Suppose $\rho = 0$ and $\gamma_{t} \leq \frac{1}{6L}$, then for any $\lambda$:

    \begin{align}
        \E [V_t] \leq
        \begin{cases}
            (H-1) \sigma^2 \gamma^2 & \text{for constant stepsizes } \gamma_t \equiv \gamma \\
            \\
            \frac{2 (M - 1) (H - 1) \sigma^2 \gamma_{t-1}^2}{M} & \text{if } \gamma_t = \frac{2}{\lambda(\xi + t + 1)} \text{ where } \xi \geq 0
            \\
            \\
            \frac{2 (M-1) (H-1) \sigma^2 \gamma_{t-K+1 \land 0}}{M} & \text{for any non-increasing } \gamma_t
        \end{cases}
    \end{align}


    \item[(b)] Suppose $\lambda > 0$ and $\gamma_{t} \leq \min \{ \frac{\lambda}{12\rho L^2}, \frac{1}{12L} \}$. Then for any $\rho$:
    \begin{align}
        \E [V_t]
        \leq
        a \gamma_{t}^2 \sigma^2 +
        \rho \gamma_{t}^2 L^2 \summ{j=t-a}{t}
        (1 - \frac{\gamma_{j} \lambda} {12})^{(t-j)}
        \cdot \E \norm{r_j}^2
    \end{align}
    Where $a = t \mod H$.
    \end{itemize}

    

\end{lemma}

\begin{proof}
    We defer the proofs from point (a) to \cite{Khaled} and \cite{Woodworth} (Sublemmas \ref{sublem:vt=0_khaled}, \ref{sublem:vt=0_woodworth}) and present the proof of point (b) in Sublemma \ref{sublem:vt>0}
\end{proof}

\begin{sublemma} \label{sublem:vt=0_khaled}
If $\rho = 0$ and $\gamma_{t} \equiv \gamma \leq \frac{1}{6L}$, then for any $\lambda$

    \begin{align}
        \E [V_t] 
        \leq
         (H-1) \gamma^2 \sigma^2
    \end{align}

\end{sublemma}

\begin{proof}
    This is Lemma 1 from \cite{Khaled}. 
\end{proof}

\begin{sublemma} \label{sublem:vt=0_woodworth}
If $\rho = 0$ then 

\begin{align}
    \E [V_t] \leq
        \begin{cases}
            \frac{2 (M - 1) (H - 1) \sigma^2 \gamma_{t-1}^2}{M} & \text{if } \gamma_t = \frac{2}{\lambda(\xi + t + 1)} \text{ where } \xi \geq 0
            \\
            \\
            \frac{2 (M-1) (H-1) \sigma^2 \gamma_{t-K+1 \land 0}}{M} & \text{for any non-increasing } \gamma_t
        \end{cases}
\end{align}

\end{sublemma}

\begin{proof}
    This is Lemma 5 from \cite{Woodworth}.
\end{proof}


\begin{sublemma} \label{sublem:vt_base}
    \begin{align}
        \E [V_{t+1}]
        &\leq
        (1 - \frac {\gamma_{t} \lambda}{6} + \gamma_{t}^2 \rho L^2) V_t
        +  \gamma_{t}^2 \sigma^2 + \gamma_{t}^2 \rho L^2 \norm{r_t}^2
    \end{align}
\end{sublemma}

\begin{proof}
    We follow the of \cite{Khaled} in proving their's Lemma 1 but under the boundaries of Assumption~\ref{ass:ass_2}.

    For $t \in \mathbb{N}$ we have $x^m_{t+1} = x^m_t - \gamma_{t} \mc{g}^m_t$ 
    and $\bar{x}_{t+1} = \bar{x}_t - \gamma_{t} \mc{\bar{g}}_t$
    if $t + 1 \mod H \neq 0$. 
    
    Hence for such $t$ and for conditioned expectation it is true that:

    \begin{align}
        \E \norm{x^m_{t+1} - \bar{x}_{t+1}}^2 
        &= \norm{x^m_t - \bar{x}_t}^2 + \gamma_{t}^2 \E \norm{\mc{g}^m_t - \mc{\bar{g}}_t}^2 - 2\gamma_{t} \E [\inner{x^m_t - \bar{x}_t}{\mc{g}^m_t - \mc{\bar{g}}_t}] \\
        &= \norm{x^m_t - \bar{x}_t}^2 + \gamma_{t}^2 \E \norm{\mc{g}^m_t - \mc{\bar{g}}_t}^2 - 2\gamma_{t} \inner{x^m_t - \bar{x}_t}{g^m_t} + 2\gamma_{t} \inner {x^m_t - \bar{x}_t}{\bar{g}_t}
    \end{align}

    Averaging over $m$:

    \begin{align}
        \E [V_{t+1}] 
        &=
        V_t + \frac{\gamma_{t}^2}{M} \summ{m=1}{M} \E \norm{\mc{g}^m_t - \mc{\bar{g}}_t}^2 - \frac{2\gamma_{t}}{M} \summ{m=1}{M} \inner{x^m_t - \bar{x}_t}{g^m_t} + 2\gamma_{t} \inner {\bar{x}_t - \bar{x}_t}{\bar{g}_t}  \\
        &=
        V_t + \frac{\gamma_{t}^2}{M} \summ{m=1}{M} \E \norm{\mc{g}^m_t - \mc{\bar{g}}_t}^2 - \frac{2\gamma_{t}}{M} \summ{m=1}{M} \inner{x^m_t - \bar{x}_t}{g^m_t} \label{eq:1904_4}
    \end{align}

    By expanding square:

    \begin{align} 
        \E \norm{\mc{g}^m_t - \mc{\bar{g}}_t}^2
        &= \E \norm{\mc{g}^m_t - \bar{g}_t + \bar{g}_t - \mc{\bar{g}}_t}^2 \\
        &= 
        \E \norm{\mc{g}^m_t - \bar{g}_t}^2 + \E \norm{\mc{\bar{g}}_t - \bar{g}_t}^2 + 2\E [\inner{\mc{g}^m_t - \bar{g}_t}{\bar{g}_t - \mc{\bar{g}}_t}] \label{eq:1904_1}
    \end{align}

    And again:

    \begin{align}
        \E \norm{\mc{g}^m_t - \bar{g}_t}^2 
        &= \E \norm{\mc{g}^m_t - g^m_t + g^m_t - \bar{g}_t}^2 \\
        &= \E \norm{\mc{g}^m_t - g^m_t}^2 
        + \norm{g^m_t - \bar{g}_t}^2
        + 2\E[\inner{\mc{g}^m_t - g^m_t}{g^m_t - \bar{g}_t}] \\
        &= \E \norm{\mc{g}^m_t - g^m_t}^2 
        + \norm{g^m_t - \bar{g}_t}^2
        + 2 \inner{g^m_t - g^m_t}{g^m_t - \bar{g}_t} \\
        &= \E \norm{\mc{g}^m_t - g^m_t}^2 
        + \norm{g^m_t - \bar{g}_t}^2 \label{eq:1904_2}
    \end{align}

    Combining \eqref{eq:1904_1} and \eqref{eq:1904_2} we have:

    \begin{align}
        \E \norm{\mc{g}^m_t - \mc{\bar{g}}_t}^2
        &= \E \norm{\mc{g}^m_t - g^m_t}^2 
        + \norm{g^m_t - \bar{g}_t}^2 + \E \norm{\mc{\bar{g}}_t - \bar{g}_t}^2 + 2\E [\inner{\mc{g}^m_t - \bar{g}_t}{\bar{g}_t - \mc{\bar{g}}_t}]
    \end{align}

    By averaging both sides over $m$:

    \begin{align}
        \fsumm{m=1}{M} \E \norm{\mc{g}^m_t - \mc{\bar{g}}_t}^2
        &= \fsumm{m=1}{M} \E \norm{\mc{g}^m_t - g^m_t}^2 
        + \fsumm{m=1}{M} \norm{g^m_t - \bar{g}_t}^2 \\
        &+ \E \norm{\mc{\bar{g}}_t - \bar{g}_t}^2 
        + 2\E [\inner{\mc{\bar{g}}_t - \bar{g}_t}{\bar{g}_t - \mc{\bar{g}}_t}] \\
        &= \fsumm{m=1}{M} \E \norm{\mc{g}^m_t - g^m_t}^2 
        + \fsumm{m=1}{M} \norm{g^m_t - \bar{g}_t}^2 \\
        &+ \E \norm{\mc{\bar{g}}_t - \bar{g}_t}^2 
        - 2\E \norm{\mc{\bar{g}}_t - \bar{g}_t}^2 \\
        &= \fsumm{m=1}{M} \E \norm{\mc{g}^m_t - g^m_t}^2 
        + \fsumm{m=1}{M} \norm{g^m_t - \bar{g}_t}^2
        - \E \norm{\mc{\bar{g}}_t - \bar{g}_t}^2 \\
        &\leq \fsumm{m=1}{M} \E \norm{\mc{g}^m_t - g^m_t}^2 
        + \fsumm{m=1}{M} \norm{g^m_t - \bar{g}_t}^2 \label{eq:1904_3}
    \end{align}

    We can estimate second term here as follows:
    \begin{align}
        \fsumm{m=1}{M} \norm{g^m_t - \bar{g}_t}^2 
        &=
        \fsumm{m=1}{M} \norm{g^m_t - \nabla F(\bar{x}_t) + \nabla F(\bar{x}_t) - \bar{g}_t}^2 \\
        &=
        \fsumm{m=1}{M} \left( \norm{g^m_t - \nabla F(\bar{x}_t)}^2 + \norm{\nabla F(\bar{x}_t) - \bar{g}_t}^2 + 2 \inner{g^m_t - \nabla F(\bar{x}_t)}{\nabla F(\bar{x}_t) - \bar{g}_t} \right) \\
        &= 
        \fsumm{m=1}{M} \norm{g^m_t - \nabla F(\bar{x}_t)}^2 + \norm{\nabla F(\bar{x}_t) - \bar{g}_t}^2 - 2 \norm{\nabla F(\bar{x}_t) - \bar{g}_t}^2 \\
        &= 
        \fsumm{m=1}{M} \norm{g^m_t - \nabla F(\bar{x}_t)}^2 - \norm{\nabla F(\bar{x}_t) - \bar{g}_t}^2 \\
        &\leq 
        \fsumm{m=1}{M} \norm{g^m_t - \nabla F(\bar{x}_t)}^2
        =
        \fsumm{m=1}{M} \norm{\nabla F(x^m_t) - \nabla F(\bar{x}_t)}^2 \\
        &\overset{~\ref{cor:nesterov}}{\leq}
        \fsumm{m=1}{M} 2L (F(\bar{x}_t) - F(x^m_t) - \inner{\bar{x}_t - x^m_t}{\nabla F(x^m_t)}) \\
        &\overset{Jensen's \ ineq.}{\leq}
        \frac{2L}{M} \summ{m=1}{M} \inner{x^m_t - \bar{x}_t}{\nabla F(x^m_t)}
        \label{eq:2004_1}
    \end{align}

    Substituting \eqref{eq:2004_1} into \eqref{eq:1904_3} and bounding variance:

    \begin{align}
        \fsumm{m=1}{M} \E \norm{\mc{g}^m_t - \mc{\bar{g}}_t} 
        &\leq
        \fsumm{m=1}{M} \E \norm{\mc{g}^m_t - g^m_t}^2 
        +
        \frac{2L}{M} \summ{m=1}{M} \inner{x^m_t - \bar{x}_t}{\nabla F(x^m_t)} \\
        &\overset{~\ref{lem:rho_2}}{\leq}
        \sigma^2 + \rho L^2 V_t + \rho L^2 \norm{r_t}^2
        +
        \frac{2L}{M} \summ{m=1}{M} \inner{x^m_t - \bar{x}_t}{\nabla F(x^m_t)}
    \end{align}

    Let us substitute this result into \eqref{eq:1904_4}:

    \begin{align}
        \E [V_{t+1}] 
        &=
        V_t + \frac{\gamma_{t}^2}{M} \summ{m=1}{M} \E \norm{\mc{g}^m_t - \mc{\bar{g}}_t}^2 - \frac{2\gamma_{t}}{M} \summ{m=1}{M} \inner{x^m_t - \bar{x}_t}{\nabla F(x^m_t)} \\
        &\leq 
        V_t 
        + \gamma_{t}^2 \sigma^2 + \gamma_{t}^2 \rho L^2 V_t + \gamma_{t}^2 \rho L^2 \norm{r_t}^2
        \\
        &+\frac{2 \gamma_{t}^2 L}{M} \summ{m=1}{M} \inner{x^m_t - \bar{x}_t}{\nabla F(x^m_t)}
        - \frac{2\gamma_{t}}{M} \summ{m=1}{M} \inner{x^m_t - \bar{x}_t}{\nabla F(x^m_t)} \\
        &=
        V_t 
        + \gamma_{t}^2 \sigma^2 + \gamma_{t}^2 \rho L^2 V_t + \gamma_{t}^2 \rho L^2 \norm{r_t}^2
        - \frac{2\gamma_{t}}{M}(1 - \gamma_{t} L) \summ{m=1}{M} \inner{x^m_t - \bar{x}_t}{\nabla F(x^m_t)}
        \label{eq:1904_5}
    \end{align}

    Now let us analyize last term. We know that $\gamma_{t} \leq \frac{1}{6L}$, therefore $1 - \gamma_{t} L \geq 0$. Thus, by strong convexity and Jensen's inequality:

    \begin{align}
        &- \frac{2\gamma_{t}}{M}(1 - \gamma_{t} L) \summ{m=1}{M} \inner{x^m_t - \bar{x}_t}{\nabla F(x^m_t)} 
        =
        \frac{2\gamma_{t}}{M}(1 - \gamma_{t} L) \summ{m=1}{M} \inner{\bar{x}_t - x^m_t}{\nabla F(x^m_t)} \\
        &\overset{~\ref{ass:ass_1}}{\leq}
        \frac{2\gamma_{t}}{M}(1 - \gamma_{t} L) \summ{m=1}{M} \left(F(\bar{x}_t) - F(x^m_t) - \frac{\lambda}{2} \norm{x^m_t - \bar{x}_t}^2 \right) \\
        &\overset{Jensen's \ ineq.}{\leq}
        - \frac{\gamma_{t}}{M}(1 - \gamma_{t} L) \summ{m=1}{M} \lambda \norm{x^m_t - \bar{x}_t}^2 
        =
        - \gamma_{t} (1 - \gamma_{t} L) \lambda V_t
        \label{eq:1904_6}
    \end{align}

    Plugging \eqref{eq:1904_6} into \eqref{eq:1904_5} and again using that $\gamma_{t} \leq \frac{1}{6L}$:

    \begin{align}
        \E [V_{t+1}]
        &\leq
        V_t 
        + \gamma_{t}^2 \sigma^2 + \gamma_{t}^2 \rho L^2 V_t + \gamma_{t}^2 \rho L^2 \norm{r_t}^2
        - \gamma_{t} (1 - \gamma_{t} L) \lambda V_t \\
        &=
        (1 - \gamma_{t} (1 - \gamma_{t} L) \lambda) V_t
        + \gamma_{t}^2 \sigma^2 + \gamma_{t}^2 \rho L^2 V_t + \gamma_{t}^2 \rho L^2 \norm{r_t}^2 \\
        &\leq
        (1 - \frac {\gamma_{t} \lambda}{6}) V_t
        + \gamma_{t}^2 \sigma^2 + \gamma_{t}^2 \rho L^2 V_t + \gamma_{t}^2 \rho L^2 \norm{r_t}^2 \\
        &=
        (1 - \frac {\gamma_{t} \lambda}{6} + \gamma_{t}^2 \rho L^2) V_t
        +  \gamma_{t}^2 \sigma^2 + \gamma_{t}^2 \rho L^2 \norm{r_t}^2
        \label{eq:1904_7} 
    \end{align}     
\end{proof}


\begin{sublemma} \label{sublem:vt>0}
Under the assumptions of Lemma~\ref{lem:lemma_Vt},

    \begin{align}
        \E [V_t] 
        \leq
         (H-1) \gamma_{t}^2 \sigma^2 +
        (H-1) \rho \gamma_{t}^2 L^2 \E \norm{r_t}^2
    \end{align}

\end{sublemma}

\begin{proof}
    We have $ \gamma_{t} \leq \frac{\lambda}{12\rho L^2} $, which means that $-\frac{\gamma_{t} \lambda }{6} + \gamma_{t}^2 \rho L^2 \leq -\frac{\gamma_{t} \lambda}{12}$. By substituting this into the result of Sublemma~\ref{sublem:vt_base} we get:
    \begin{align}
        \E [V_{t+1}]
        &\leq
        (1 - \frac {\gamma_{t} \lambda}{12}) V_t
        + \gamma_{t}^2 \sigma^2 + \gamma_{t}^2 \rho L^2 \norm{r_t}^2
        \label{eq:2204_1}
    \end{align}
    

    Let us divide $t$ by $H$, suppose $t = kH + a; \ k, a \in \mathbb{N}; \ a < H$.
    Recalling that $V_{kH} = 0$, recursing~\eqref{eq:2204_1} and considering $\E$ as a full expectation yields:
    
    \begin{align}
        \E [V_{t}]
        &\leq
        (1 - \frac{\gamma_{t} \lambda}{12})^a  \cdot V_{kH} 
        +
        \summ{j=kH}{kH+a}
        (1 - \frac{\gamma_{t} \lambda} {12})^{(t-j)}
        \cdot
        \left(
        \rho \gamma_{t}^2 L^2 \E \norm{r_j}^2 + \gamma_{t}^2 \sigma^2
        \right) \\
        &=
        \summ{j=kH}{kH+a}
        (1 - \frac{\gamma_{j} \lambda} {12})^{(t-j)}
        \cdot 
        \left(
        \rho \gamma_{j}^2 L^2 \E \norm{r_j}^2 + \gamma_{t}^2 \sigma^2
        \right) \\
        &\leq
        a \gamma_{t}^2 \sigma^2 +
        \rho \gamma_{t}^2 L^2 \summ{j=t-a}{t}
        (1 - \frac{\gamma_{j} \lambda} {12})^{(t-j)}
        \cdot \E \norm{r_j}^2 
    \end{align}
\end{proof}
