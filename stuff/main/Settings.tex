\subsection{Settings} \label{subsec:settings}

%Convexity and nabla-Lipschitzness
\begin{assumption} \label{ass:ass_1}
    Assume that $F$ is $\mu$-strongly convex and $L$-smooth. That is, $\forall x, y \in \mathbb{R}^d$,
    \[
    \frac{\mu}{2} \norm{x - y}^2 \leq F(y) - F(x) - \inner{\nabla F(x)}{y-x} \leq \frac{L}{2} \norm {x-y}^2
    \]
\end{assumption}

\begin{corollary} \label{cor:nesterov}
Under assumption~\ref{ass:ass_1}
    \[
    \frac{1}{2L} \norm{\nabla F(x) - \nabla F(y)} \leq F(y) - F(x) - \inner{\nabla F(x)}{y-x}
    \]
\end{corollary}
\proof{
    This is Theorem 2.1.5 in \cite{Nesterov}
}

%Bounded stochastic gradient variance
\begin{assumption} \label{ass:ass_2}
    Assume that for stochastic gradient variance is bounded, i.e. exists such $\sigma$ that:
    \[\E_{z \sim \mathcal{D}} \norm {\nabla F(x, z) - \nabla F(x)}^2 \leq \sigma^2
    + \rho \norm{\nabla F(x)}^2 \]
\end{assumption}

%F=Q+R decomposition
\begin{statement} \label{st:st_1}
    Objective function can be decomposed as $F = Q + R$, where $Q$ is a quadratic function that is $\mu_Q$-convex and $L_Q$-smooth, and $R$ is $\mu_R$-convex and $L_R$-smooth. Than we denote parameter
    \(\varepsilon := \frac{L_R}{L}\)
    which gives us an idea of how far $F$ is from a quadratic function.
\end{statement}

Note that such decomposition always takes place beacuse we can take $Q = 0$ and $R = F$.


In prospect of statement ~\ref{st:st_1}, following takes place:
\begin{corollary} \label{cor:linearity}
    $\nabla Q$ is a linear function
\end{corollary}

\begin{corollary}
    \(\varepsilon \leq 1\)
\end{corollary}

\begin{corollary} \label{cor:mu}
    \(\mu_Q + \mu_R \leq \mu\)
\end{corollary}